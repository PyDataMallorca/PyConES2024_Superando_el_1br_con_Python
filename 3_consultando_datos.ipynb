{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e70118a4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "# Superando el reto del billón de filas con Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f55c8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import generate_sample_data, generate_heatmap\n",
    "\n",
    "from pathlib import Path\n",
    "import csv\n",
    "from zipfile import ZipFile\n",
    "from io import TextIOWrapper\n",
    "import shutil\n",
    "import timeit\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import pyarrow as pa\n",
    "import pyarrow.feather as feather\n",
    "import duckdb\n",
    "import ibis\n",
    "import modin.pandas as mpd\n",
    "import dask.dataframe as dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b93141",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('.')\n",
    "(path / 'data').mkdir(mode=0o775, exist_ok=True)\n",
    "path_data = path / 'data'\n",
    "filename = \"sample50M\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c54fff",
   "metadata": {},
   "source": [
    "# ¿Qué vamos a hacer?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9827ee95",
   "metadata": {},
   "source": [
    "* Vamos a seleccionar 2 operaciones de consulta sobre los datos cargados en memoria.\n",
    "* Vamos a reflexionar sobre operaciones costosas y operaciones más ligeras.\n",
    "* Vamos a ejecutar estas operaciones sobre las combinaciones de ficheros y herramientas que parecen cargar más rápidamente los datos en memoria y compararemos los resultados.\n",
    "* ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "688b98eb",
   "metadata": {},
   "source": [
    "# Operaciones a ejecutar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c3c776",
   "metadata": {},
   "source": [
    "Ejecutaremos 2 operaciones de consulta y compararemos su rendmiento:\n",
    "1. Primero, una operación sencilla como un simple conteo de filas: operación **count**.\n",
    "2. Y segundo, una operación más compleja, como calcular la media por tipo de producto y ordenar los resultados de forma decreciente por media: operación **average**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd30dcc1",
   "metadata": {},
   "source": [
    "Preguntas:\n",
    "* ¿De qué forma podríamos implementar estas operaciones sobre un fichero CSV?\n",
    "* ¿Y cómo podríamos aprovechar al máximo nuestras CPUs para que la ejecución sea más rápida?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b3a6eb",
   "metadata": {},
   "source": [
    "Algunas preguntas adicionales:\n",
    "* Para hacer un conteo de filas, ¿necesitamos leer todas las columnas?\n",
    "* En el caso de ficheros como Parquet que contienen metadatos, ¿los podríamos usar para acelerar el conteo de filas?\n",
    "* En el cálculo de la media, ¿qué operación es la más costosa?, ¿el cálculo de la media?, ¿hacer la agrupación de valores?, ¿la ordenación por medias final?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3cb4334",
   "metadata": {},
   "source": [
    "# Selección de formatos y herramientas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dccc2c51",
   "metadata": {},
   "source": [
    "Dado que en la sección anterior hemos analizar los formatos y herramientas más convenientes para nuestro objetivo, vamos a centrarnos en este notebook en los que nos han dado mejor rendimiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45da5736",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados = pd.DataFrame(\n",
    "    index=('duckdb', 'polars', 'pyarrow'),\n",
    "    columns=(\n",
    "        'csv - count',\n",
    "        'feather - count',\n",
    "        'feather - average',\n",
    "        'parquet - count',\n",
    "        'parquet - average',\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e46a24",
   "metadata": {},
   "source": [
    "Importante: vamos a ejecutar las dos operaciones cargando cada vez los datos, cuando lo recomendable sería cargar los datos primero y ejecutar ambas operaciones con los datos ya cargados en memoria, para evitar que en la segunda operación tengamos que cargar los datos otra vez. De esta forma podremos comparar mejor el rendimiento de las herramientas y formatos que usaremos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d8023d",
   "metadata": {},
   "source": [
    "# Consulto Feather con PyArrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea972de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_with_feather_pyarrow():\n",
    "    with pa.memory_map(f'{path_data}/{filename}.feather', 'r') as source:\n",
    "        table = pa.ipc.open_file(source).read_all()\n",
    "    return len(table)\n",
    "\n",
    "kk = %timeit -r 3 -o count_with_feather_pyarrow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab995da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados.loc['pyarrow', 'feather - count'] = kk.average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a1dcfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3eeb314",
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_with_feather_pyarrow():\n",
    "    with pa.memory_map(f'{path_data}/{filename}.feather', 'r') as source:\n",
    "        table = pa.ipc.open_file(source).read_all()\n",
    "    return table.group_by(\"product\").aggregate([\n",
    "        (\"price\", \"mean\")\n",
    "    ]).sort_by([(\"price_mean\", \"descending\")])\n",
    "\n",
    "kk = %timeit -r 3 -o average_with_feather_pyarrow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5163cbbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados.loc['pyarrow', 'feather - average'] = kk.average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1828be63",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados.transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64fa9cb",
   "metadata": {},
   "source": [
    "# Consulto Parquet con DuckDB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8706b549",
   "metadata": {},
   "source": [
    "Uno de los problemas que tenemos a la hora de medir el rendimiento de DuckDB es que tiene un sistema de caché muy efectivo. Y por lo tanto, repetir muchas veces la misma consulta lo único que hace es medir lo buena o mala que es esa caché. Por este motivo vamos a cambiar la medición para tomar únicamente 2 ejecuciones y quedarnos con la media de esos dos valores (siguiendo la idea de [H2O.ai Database-like Ops Benchmark](https://duckdb.org/2023/04/14/h2oai.html)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff674b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "kk = %timeit -r 1 -n 2 -o duckdb.sql(f\"SELECT COUNT(*) FROM read_parquet('./{str(path_data)}/{filename}.parquet')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321e07a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados.loc['duckdb', 'parquet - count'] = kk.average"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0914cf97",
   "metadata": {},
   "source": [
    "Si en lugar de usar SQL, prefieres usar Ibis, puedes escribir el mismo código de la siguiente forma:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ce0ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_with_ibis():\n",
    "    con = ibis.connect('duckdb://')\n",
    "    table = ibis.read_parquet(f'./{str(path_data)}/{filename}.parquet')\n",
    "    return table.count().execute()\n",
    "\n",
    "kk = %timeit -r 1 -n 2 -o count_with_ibis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243610c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados.transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6536fbe3",
   "metadata": {},
   "source": [
    "* ¿Por qué DuckDB con Parquet es tan rápido en el conteo?, ¿qué puede estar haciendo para tener este buen rendimiento?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e58b74",
   "metadata": {},
   "source": [
    "Probemos ahora cargando el fichero CSV..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef8cdcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "kk = %timeit -r 1 -n 2 -o duckdb.sql(f\"SELECT COUNT(*) FROM read_csv('./{str(path_data)}/{filename}.csv')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf121fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados.loc['duckdb', 'csv - count'] = kk.average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ead569d",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados.transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cdd1478",
   "metadata": {},
   "source": [
    "El principal motivo es que DuckDB utiliza los metadatos que el fichero Parquet contiene para que su ejecución sea muy rápida y evita tener que cargar todos los datos del fichero Parquet en memoria para calcular el conteo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a2667d",
   "metadata": {},
   "source": [
    "Veamos ahora qué tal se comporta en el cálculo de la media por producto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dbb5498",
   "metadata": {},
   "outputs": [],
   "source": [
    "kk = %timeit -r 1 -n 2 -o duckdb.sql(f\"SELECT product, AVG(price) FROM read_parquet('./{str(path_data)}/{filename}.parquet') GROUP BY product ORDER BY AVG(price) DESC\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab627228",
   "metadata": {},
   "source": [
    "DuckDB sigue la siguiente estrategia para ejecutar la anterior instrucción:\n",
    "1. Crear tantos hilos como CPUs haya disponibles en nuestro PC.\n",
    "2. Cada uno de estos hilos se encargan de leer una parte diferente del fichero Parquet hasta que ya no quedan filas por leer (más información: https://duckdb.org/2024/07/09/memory-management.html).\n",
    "3. Para almacenar los resultados, crea una tabla hash en la memoria principal en la que cada clave de la tabla es un producto (A, B, C, D, E o F).\n",
    "4. Si esa tabla hash no cabe en la memoria principal, escribe partes de esta tabla hash en la memoria secundaria (más información: https://duckdb.org/2024/03/29/external-aggregation.html). Y si no hay espacio suficiente en la memoria secundaria da un error por falta de memoria.\n",
    "5. Y después de leer todas las filas del fichero Parquet devuelve los resultados después de ordenarlos en memoria principal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0284eeaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados.loc['duckdb', 'parquet - average'] = kk.average"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d842439",
   "metadata": {},
   "source": [
    "También, si en lugar de usar SQL prefieres utilizar Ibis, podrías escribir el mismo código de la siguiente forma:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64aa8c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_with_ibis():\n",
    "    con = ibis.connect('duckdb://')\n",
    "    table = ibis.read_parquet(f'./{str(path_data)}/{filename}.parquet')\n",
    "    return (table.group_by('product')\n",
    "            .aggregate(avg_price=table['price'].mean())\n",
    "            .order_by(ibis.desc('avg_price'))\n",
    "            .execute())\n",
    "\n",
    "kk = %timeit -r 1 -n 2 -o average_with_ibis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236dc879",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados.transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe97da8f",
   "metadata": {},
   "source": [
    "# Consulto Parquet con Polars"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0510b8c5",
   "metadata": {},
   "source": [
    "En Polars también podemos utilizar los metadatos de Parquet para optimizar el conteo de filas. Para ello, debemos usar el tipo `LazyFrame` y el método `collect()` que evita cargar el fichero Parquet en la memoria principal para contar las filas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe4cdf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_with_parquet_polars():\n",
    "    lf = pl.scan_parquet(path_data / f\"{filename}.parquet\")\n",
    "    return lf.select(pl.len()).collect()\n",
    "    \n",
    "kk = %timeit -r 3 -o count_with_parquet_polars()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2799a2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados.loc['polars', 'parquet - count'] = kk.average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f217b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6acb7bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_with_parquet_polars():\n",
    "    lf = pl.scan_parquet(path_data / f\"{filename}.parquet\")\n",
    "    return lf.group_by(\"product\").mean().sort(\"price\", descending=True).collect()\n",
    "\n",
    "kk = %timeit -r 3 -o average_with_parquet_polars()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a237d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados.loc['polars', 'parquet - average'] = kk.average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde36106",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados.transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24076078",
   "metadata": {},
   "source": [
    "En este caso vemos que el tiempo dedicado en la operación **average** es mucho mayor que en el conteo, ¿cómo podríamos saber a qué operaciones dedica más tiempo Polars?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce6cc23",
   "metadata": {},
   "source": [
    "Una forma muy sencilla de hacerlo es usar `profile()` en lugar de `collect()`. También, podemos pasar el parámetro `profile(show_plot=True)` para ver adicionalmente un gráfico con matplotlib. Por ejemplo, para el conteo de filas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d63327c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lf = pl.scan_parquet(path_data / f\"{filename}.parquet\")\n",
    "lf.select(pl.len()).profile(show_plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4c654d",
   "metadata": {},
   "source": [
    "¿Podrías hacer lo mismo para la operación **average**?, ¿qué conclusiones podemos sacar de los resultados obtenidos?, ¿se te ocurre alguna forma de acelerar el nodo más lento?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8765a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escribe aquí el código para mostrar el tiempo dedicado a cada paso para el cálculo de la operación average en Polars\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72bf865c",
   "metadata": {},
   "source": [
    "Finalmente, representaremos los datos obtenidos para visualizar de manera más clara la comparación entre todos los resultados de esta sección."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7740155b",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_heatmap(resultados.transpose(), 'Heatmap de los tiempos de consulta de datos (seg.).')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32191679",
   "metadata": {},
   "source": [
    "# Ejercicio final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e44c7e8",
   "metadata": {},
   "source": [
    "Una vez que hemos visto diferentes técnicas y formatos de ficheros, ¿cuál es el tamaño máximo de fichero que puedes ejecutar en tu portátil? Escoge un formato de fichero y una herramienta e intenta ver cuál es el tamaño máximo que puedes ejecutar en un tiempo razonable tanto para la operación **average** (por ejemplo, menos de 60 segundos)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da2d008",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Genera primero los ficheros que necesites...\n",
    "\n",
    "# Por ejemplo, si quieres generar un Parquet de 500M de filas puedes hacerlo con la siguiente instrucción:\n",
    "generate_sample_data(\n",
    "    lines=500_000_000,\n",
    "    fmt = 'parquet',\n",
    "    filename = f'{str(path_data)}/sample500M'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ccb6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escribe aquí el código para calcular la operación average con el máximo número de filas que puedas en menos de 60 segundos\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab2fa86a",
   "metadata": {},
   "source": [
    "## Apéndice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac2026b",
   "metadata": {},
   "source": [
    "Aquí mostramos tiempos del código anterior ejecutado en otros PCs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911e6b04",
   "metadata": {},
   "source": [
    "---\n",
    "SO: linux (Kernel: 5.15.0-122-generic x86_64)\n",
    "\n",
    "Procesador: AMD Ryzen 9 3900X (cache: L1: 768 KiB L2: 6 MiB L3: 64 MiB)\n",
    "\n",
    "HDD: Crucial model: CT1000BX500SSD1 size: 931.51 GiB speed: 6.0 Gb/s type: SSD serial\n",
    "\n",
    "RAM: 16GiB DIMM DDR4 Speed 2666 MT/s (x 4) = 64 GiB\n",
    "\n",
    "![Resultados](./images/resultados_kiko_desktop_linux_consultando.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25664e3d",
   "metadata": {},
   "source": [
    "---\n",
    "SO: Windows 10 Enterprise (64 bits)\n",
    "\n",
    "Procesador: 13th Gen Intel(R) Core(TM) i7-1365U\n",
    "\n",
    "HDD: NVMe CL4-3D512-Q11 NVMe SSSTC 512GB\n",
    "\n",
    "RAM: 2 x 8 GB 3200 MHz DDR4-SDRAM = 16 GB \n",
    "\n",
    "![Resultados](./images/resultados_kiko_pccurr_windows_consultando.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df58087",
   "metadata": {},
   "source": [
    "---\n",
    "SO: macOS Sequoia (15.0)\n",
    "\n",
    "Procesador: Apple M2 con 8 núcleos\n",
    "\n",
    "HDD: APPLE SSD AP0512Z 512 GB\n",
    "\n",
    "RAM: LPDDR5 16 GB\n",
    "\n",
    "![Resultados](./images/resultados_jordi_mba_consultando.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c6f523",
   "metadata": {},
   "source": [
    "---\n",
    "SO: Windows 11 Pro 2 (64 bits)\n",
    "\n",
    "Procesador: 14th Intel(R) Core(TM) i7-14700HX  \n",
    "\n",
    "HDD: NVMe™ TLC M.2 de 1 TB SSD \n",
    "\n",
    "RAM: 32 GB de RAM DDR5-4800 MHz (2 x 16 GB)\n",
    "\n",
    "![Resultados](./images/resultados_ernesto_windows_consultando.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
